import chromadb
from langchain_huggingface import HuggingFaceEmbeddings

client = chromadb.HttpClient(host="localhost", port=8000)
collection = client.get_collection(name="langchain")

query = "æ²ˆè€äºŒæ˜¯è°ï¼Ÿæ–‡ä¸­æœ‰æåŠåˆ°æ²ˆè€äºŒå—ï¼Ÿ"
embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-m3")
query_embedding = embedding_model.embed_query(query)

# å‘é‡æ£€ç´¢
semantic_results = collection.query(
    query_embeddings=[query_embedding],
    n_results=5
)

# # å…³é”®è¯æ£€ç´¢
# keyword_results = collection.query(
#     query_texts=[query],  # Chroma æ”¯æŒ query_textsï¼Œä½†æ•ˆæœä¸å¼º
#     n_results=10,
#     where_document={"$contains": "æ²ˆè€äºŒ"}
# )
#
# # æ‰“å°è¯­ä¹‰ç»“æœ
# print("\n=== ğŸ” è¯­ä¹‰ç»“æœ ===")
# for i, doc in enumerate(semantic_results["documents"][0]):
#     print(f"\nResult {i+1}: {doc}")

# # æ‰“å°å…³é”®è¯ç»“æœ
# print("\n=== ğŸ” å…³é”®è¯å¼ºåˆ¶åŒ¹é…ç»“æœ ===")
# for i, doc in enumerate(keyword_results["documents"][0]):
#     print(f"\nResult {i+1}: {doc}")

print("\n=== æŸ¥è¯¢ç»“æœ ===")
for i, doc in enumerate(semantic_results["documents"][0]):
    print(f"\nResult {i+1}: {doc}")